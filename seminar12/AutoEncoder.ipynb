{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQfNblvHva3l"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adasegroup/ML2022_seminars/blob/master/seminar14/seminar_dim_reduction_autoencoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1b2K12Xva3n"
      },
      "source": [
        "# Seminar: Dimensionality reduction. Autoencoding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FOBg6tyva3o"
      },
      "source": [
        "__Autoencoders__ or how it was on the lectures - replicational neural networks - are unsupervised artificial neural network that learns how to efficiently compress and encode data then learns how to reconstruct the data back from the reduced encoded representation to a representation that is as close to the original input as possible.\n",
        "\n",
        "It is good for:\n",
        "* redusing noise in the data\n",
        "* building stable networks for data invariants\n",
        "* data compression\n",
        "\n",
        "The encoder brings the data from a high dimensional input to a __Latent space__ or *bottleneck* layer, where the number of neurons is the smallest. Then, the decoder takes this encoded input and converts it back to the original input shape — in our case an image. The latent space is the space in which the data lies in the bottleneck layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmC4aFCGva3q"
      },
      "source": [
        "<img src=\"https://www.compthree.com/images/blog/ae/ae.png\" alt=\"Drawing\" style=\"width: 700px;\" />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qz4Y2Ql8va3s"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as torch_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbxXx2sGva3t"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "data = fetch_olivetti_faces(shuffle=True, random_state= 42 ).data\n",
        "target = fetch_olivetti_faces(shuffle=True, random_state= 42).target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, stratify=target, test_size=0.33, random_state=42)\n",
        "\n",
        "\n",
        "#data\n",
        "plt.figure(figsize=(12, 5))\n",
        "for i in range(40):\n",
        "    plt.subplot(4, 10, i + 1)\n",
        "    plt.imshow(data[i].reshape((64, 64)), cmap='gray')\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yQGA2ufva3u"
      },
      "source": [
        "#### 1. Write `torch` compatible dataset and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2SDCuqW2va3u"
      },
      "outputs": [],
      "source": [
        "class FacesData(torch_data.Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        super(FacesData, self).__init__()\n",
        "        self.X = torch.from_numpy(X)\n",
        "        self.y = y.astype(int)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx].unsqueeze(0), self.y[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlYelX2-va3v"
      },
      "outputs": [],
      "source": [
        "train_dset = FacesData(X_train, y_train)\n",
        "test_dset = FacesData(X_test, y_test)\n",
        "\n",
        "tsr_im, cls = train_dset[5]\n",
        "plt.imshow(tsr_im.view(64, 64))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5R8UkBoqva3x"
      },
      "source": [
        "#### 2. Write Autoencoder model as object of  `torch.nn.Module` class\n",
        "\n",
        "It takes as input encoder and decoder (it will be small neural networks)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4sv40Arhva3y"
      },
      "outputs": [],
      "source": [
        "class MyFirstAE(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(MyFirstAE, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Take a mini-batch as an input, encode it to the latent space and decode back to the original space\n",
        "        x_out = decoder(encoder(x))\n",
        "        :param x: torch.tensor, (MB, x_dim)\n",
        "        :return: torch.tensor, (MB, x_dim)\n",
        "        \"\"\"\n",
        "        z =  ### YOUR CODE HERE ###\n",
        "        x_out = ### YOUR CODE HERE ###\n",
        "        return x_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzfOhbzHva3z"
      },
      "source": [
        "#### 3. Define Encoder and Decoder, whey will be symmetrical\n",
        "\n",
        "You should define variable for bottelneck layer - `hid` and for number of neurons in the whole network  - `ss`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dQVficSxva30"
      },
      "outputs": [],
      "source": [
        "ss = 128\n",
        "\n",
        "samples, sample_size = data.shape\n",
        "\n",
        "encoder = lambda hid: nn.Sequential(\n",
        "                        nn.Linear(sample_size, ss*4),\n",
        "                        nn.LeakyReLU(inplace=True),\n",
        "                        nn.Dropout(0.2),\n",
        "                        nn.Linear(ss*4, ss*2),\n",
        "                        nn.LeakyReLU(inplace=True),\n",
        "                        nn.Dropout(0.2),\n",
        "                        nn.Linear(ss*2, hid)\n",
        "                        )\n",
        "\n",
        "decoder =  lambda hid: nn.Sequential(\n",
        "                        nn.Linear(hid, ss*2),\n",
        "                        nn.LeakyReLU(inplace=True),\n",
        "                        nn.Dropout(0.2),\n",
        "                        nn.Linear(ss*2, ss*4),\n",
        "                        nn.LeakyReLU(inplace=True),\n",
        "                        nn.Dropout(0.2),\n",
        "                        nn.Linear(ss*4, sample_size),\n",
        "                        nn.Sigmoid(),\n",
        "                        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z51yh37Hva31"
      },
      "source": [
        "#### 4. Defining criterion, optimizer, scheduler and data loaders\n",
        "\n",
        "Choose criterion, it will be `nn.MSEloss` for now, optimizer and scheduler for optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Nj6KAUtava32"
      },
      "outputs": [],
      "source": [
        "device = 'cuda:0'\n",
        "#device = 'cpu'\n",
        "\n",
        "net = MyFirstAE(encoder(50), decoder(50))\n",
        "criterion = nn.MSELoss()\n",
        "optimizer =  ### YOUR CODE HERE ###  # Adam with lr = 1e-3\n",
        "scheduler =  ### YOUR CODE HERE ###    # StepLR with step_size=50, gamma=0.7\n",
        "\n",
        "\n",
        "train_loader = torch_data.DataLoader(train_dset, batch_size=100, shuffle=True)\n",
        "val_loader = torch_data.DataLoader(test_dset, batch_size=100, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVICXIUPva33"
      },
      "source": [
        "#### 5. The main part - write `train` for the network\n",
        "\n",
        "Train will take the batch, send to the devise, encode and decode it and calculate the loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3t7b8q4Hva33"
      },
      "outputs": [],
      "source": [
        "def train(epochs, net, criterion, optimizer, train_loader, val_loader,scheduler=None, verbose=True, save_dir=None):\n",
        "    net.to(device)\n",
        "    for epoch in range(1, epochs+1):\n",
        "        net.train()\n",
        "        for X, _ in train_loader:\n",
        "\n",
        "            X = X.to(device)\n",
        "\n",
        "            out = net(X)\n",
        "            loss = criterion(out, X)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        net.eval()\n",
        "        for X, _ in val_loader:\n",
        "            X = X.to(device)\n",
        "            out = net(X)\n",
        "            val_loss = criterion(out, X)\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        freq = max(epochs//20,1)\n",
        "        if verbose and epoch%freq==0:\n",
        "            print('Epoch {}/{} || Loss:  Train {:.4f} | Validation {:.4f}'.format(epoch, epochs, loss.item(), val_loss.item()))\n",
        "\n",
        "    if save_dir is not None:\n",
        "        torch.save(model.state_dict(), os.path.join(save_dir, 'model.pth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHa560jcva34"
      },
      "source": [
        "#### 5. Enjoy the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUlNVB0rva34"
      },
      "outputs": [],
      "source": [
        "# for `MSE` loss lets get < 0.011 on validation, with AE \"bottleneck\" = 50\n",
        "\n",
        "train(300, net, criterion, optimizer, train_loader, val_loader, scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ryn13Yt4va35"
      },
      "outputs": [],
      "source": [
        "\n",
        "fig, ax = plt.subplots(ncols=10, nrows=2, figsize=(20, 5))\n",
        "\n",
        "n_pics = 64\n",
        "\n",
        "for i in range(10):\n",
        "    im = train_dset[i][0]\n",
        "    rec = net(im.reshape(1,n_pics**2).to(device))[0]\n",
        "    ax[0, i].imshow(im[0].reshape(n_pics,n_pics), cmap = \"gray\");\n",
        "    ax[1, i].imshow(rec.detach().cpu().reshape(n_pics,n_pics), cmap = \"gray\");\n",
        "    ax[0, i].axis('off')\n",
        "    ax[1, i].axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "qn16a7UHva35"
      },
      "outputs": [],
      "source": [
        "from matplotlib import offsetbox\n",
        "from matplotlib.offsetbox import AnnotationBbox, OffsetImage\n",
        "\n",
        "def plot_embedding(X, y, images_small=None, title=None):\n",
        "    \"\"\"\n",
        "    Nice plot on first two components of embedding with Offsets.\n",
        "\n",
        "    \"\"\"\n",
        "    # take only first two columns\n",
        "    X = X[:, :2]\n",
        "    # scaling\n",
        "    x_min, x_max = np.min(X, 0), np.max(X, 0)\n",
        "    X = (X - x_min) / (x_max - x_min)\n",
        "    plt.figure(figsize=(13,8))\n",
        "    ax = plt.subplot(111)\n",
        "\n",
        "    for i in range(X.shape[0] - 1):\n",
        "        plt.text(X[i, 0], X[i, 1], str(y[i]),\n",
        "                 color=plt.cm.RdGy(y[i]),\n",
        "                 fontdict={'weight': 'bold', 'size': 12})\n",
        "        if images_small is not None:\n",
        "            imagebox = OffsetImage(images_small[i], zoom=.4, cmap = 'gray')\n",
        "            ab = AnnotationBbox(imagebox, (X[i, 0], X[i, 1]),\n",
        "                xycoords='data')\n",
        "            ax.add_artist(ab)\n",
        "\n",
        "    if hasattr(offsetbox, 'AnnotationBbox'):\n",
        "        # only print thumbnails with matplotlib > 1.0\n",
        "        shown_images = np.array([[1., 1.]])\n",
        "        for i in range(X.shape[0]):\n",
        "            dist = np.sum((X[i] - shown_images) ** 2, 1)\n",
        "            if np.min(dist) < 4e-1:\n",
        "                # don't show points that are too close\n",
        "                continue\n",
        "    if title is not None:\n",
        "        plt.title(title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysRNBMMrva36"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "X_projected = PCA(50).fit_transform(data)\n",
        "data_pic = data.reshape((-1, 64, 64))\n",
        "plot_embedding(X_projected, target, data_pic, \"PCA. Projection on two components out of 50 first \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uY2KVzw4va36"
      },
      "outputs": [],
      "source": [
        "X_projected = net.encoder(torch.Tensor(data).to(device)).cpu().detach().numpy()\n",
        "data_pic = data.reshape((-1, 64, 64))\n",
        "plot_embedding(X_projected, target, data_pic, \"Projection AE with 50 latent features, MSE = 0.0087\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}